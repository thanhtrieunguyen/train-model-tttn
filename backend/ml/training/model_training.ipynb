{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8df8b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# matplotlib.use('Agg')\n",
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68195dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "notebook_dir = os.getcwd()\n",
    "project_root = os.path.abspath(os.path.join(notebook_dir, '../../..'))\n",
    "sys.path.append(project_root)\n",
    "from backend.ml.data.data_preprocessing import WeatherDataPreprocessor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8f351be",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "dataset_path = os.path.join(project_root, 'backend', 'ml', 'data', 'weather_dataset.csv')\n",
    "models_path = os.path.join(project_root, 'backend', 'ml', 'models', 'weather_models.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f46d0ad0",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class WeatherPredictor:\n",
    "    def __init__(self):\n",
    "        self.model = RandomForestRegressor(\n",
    "            n_estimators=100,\n",
    "            max_depth=20,\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        self.preprocessor = WeatherDataPreprocessor()\n",
    "        self.feature_list_for_scale = None\n",
    "\n",
    "    def prepare_data(self, data_path):\n",
    "        \"\"\"Prepare data for training.\"\"\"\n",
    "        df = self.preprocessor.preprocess(data_path)\n",
    "        \n",
    "        targets = ['temperature', 'humidity', 'wind_speed', 'pressure', \n",
    "                  'precipitation', 'cloud', 'uv_index', 'visibility', \n",
    "                  'rain_probability', 'dewpoint', 'gust_speed', 'snow_probability',\n",
    "                  'condition_code', 'wind_direction']\n",
    "\n",
    "        X = df.drop(targets, axis=1)\n",
    "        y_dict = {target: df[target] for target in targets}\n",
    "\n",
    "        # for target in targets:\n",
    "        #     print(f\"Distribution of {target}:\")\n",
    "        #     print(df[target].describe())\n",
    "            \n",
    "        # Tạo feature_list_for_scale sau khi tách target\n",
    "        feature_list_for_scale = [col for col in X.columns if col not in targets]\n",
    "\n",
    "        return X, y_dict, feature_list_for_scale\n",
    "    \n",
    "    def train(self, X, y_dict, feature_list_for_scale):\n",
    "        \"\"\"Train models for each weather parameter with comprehensive metrics.\"\"\"\n",
    "        self.models = {}\n",
    "        self.metrics = {}\n",
    "        self.scalers = {}\n",
    "        self.feature_importances = {}\n",
    "\n",
    "        print(\"Training models...\")\n",
    "        for target_name, y in tqdm(y_dict.items()):\n",
    "            print(f\"Training model for {target_name}...\")\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X, y, test_size=0.2, random_state=42\n",
    "            )\n",
    "\n",
    "            # Scale data\n",
    "            scaler = StandardScaler()\n",
    "            X_train_scaled = scaler.fit_transform(X_train[feature_list_for_scale])\n",
    "            X_test_scaled = scaler.transform(X_test[feature_list_for_scale])\n",
    "            \n",
    "            self.scalers[target_name] = scaler\n",
    "\n",
    "            # Train model\n",
    "            model = RandomForestRegressor(\n",
    "                n_estimators=500,\n",
    "                max_depth=20,\n",
    "                random_state=42,\n",
    "                n_jobs=-1\n",
    "            )\n",
    "            model.fit(X_train_scaled, y_train)\n",
    "            \n",
    "            # Predictions\n",
    "            y_pred = model.predict(X_test_scaled)\n",
    "            \n",
    "            # Calculate detailed metrics\n",
    "            mse = mean_squared_error(y_test, y_pred)\n",
    "            rmse = np.sqrt(mse)\n",
    "            r2 = r2_score(y_test, y_pred)\n",
    "            mae = np.mean(np.abs(y_test - y_pred))\n",
    "            mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100 if not np.any(y_test == 0) else np.nan\n",
    "            \n",
    "            # Store feature importance\n",
    "            self.feature_importances[target_name] = dict(zip(feature_list_for_scale, model.feature_importances_))\n",
    "            \n",
    "            self.models[target_name] = model\n",
    "            self.metrics[target_name] = {\n",
    "                'rmse': rmse,\n",
    "                'r2': r2,\n",
    "                'mse': mse,\n",
    "                'mae': mae,\n",
    "                'mape': mape if not np.isnan(mape) else \"N/A (contains zero values)\"\n",
    "            }\n",
    "            \n",
    "            # Plot predictions\n",
    "            self.plot_predictions(y_test, y_pred, target_name)\n",
    "        \n",
    "        print(\"Training complete.\")\n",
    "        \n",
    "        # Print comprehensive evaluation metrics\n",
    "        self.print_evaluation_metrics()\n",
    "        \n",
    "        return self.metrics\n",
    "    \n",
    "    def plot_predictions(self, y_true, y_pred, target_name):\n",
    "        \"\"\"Plot actual vs predicted values and display in notebook.\"\"\"\n",
    "        # Nếu target_name là một chuỗi (chỉ một mục tiêu), chuyển nó thành danh sách\n",
    "        if isinstance(target_name, str):\n",
    "            target_names = [target_name]\n",
    "        else:\n",
    "            target_names = target_name\n",
    "            \n",
    "        num_plots = len(target_names)\n",
    "        num_cols = 3  # Số cột mỗi hàng là 3\n",
    "        num_rows = (num_plots + num_cols - 1) // num_cols  # Tính số hàng\n",
    "\n",
    "        fig, axes = plt.subplots(num_rows, num_cols, figsize=(15, 5 * num_rows))\n",
    "        axes = axes.flatten()\n",
    "\n",
    "        for idx, target in enumerate(target_names):\n",
    "            y_true_target = y_true[target]\n",
    "            y_pred_target = y_pred[target]\n",
    "            \n",
    "            # Vẽ biểu đồ cho mỗi target\n",
    "            ax = axes[idx]\n",
    "            ax.scatter(y_true_target, y_pred_target, alpha=0.5, c='blue', s=10, label='Predicted vs Actual')\n",
    "            ax.plot([y_true_target.min(), y_true_target.max()], [y_true_target.min(), y_true_target.max()], 'r--', lw=2, label='Ideal Fit')\n",
    "            ax.set_xlabel('Actual Values')\n",
    "            ax.set_ylabel('Predicted Values')\n",
    "            ax.set_title(f'Actual vs Predicted {target}')\n",
    "            ax.legend()\n",
    "            ax.grid(True)\n",
    "\n",
    "        # Loại bỏ các axes thừa nếu không cần thiết\n",
    "        for idx in range(num_plots, len(axes)):\n",
    "            fig.delaxes(axes[idx])\n",
    "\n",
    "        # Lưu và hiển thị biểu đồ\n",
    "        save_dir = os.path.join(project_root, 'backend/ml/models/rating_chart1')\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        plt.tight_layout()  # Cải thiện layout\n",
    "        plt.savefig(f'{save_dir}/predictions_all_targets.png')\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "    \n",
    "    def save_models(self, path=None):\n",
    "        \"\"\"Save trained models and ensure directory exists.\"\"\"\n",
    "        if path is None:\n",
    "            # Use default path if none provided\n",
    "            path = os.path.join(project_root, 'backend', 'ml', 'models', 'weather_models.joblib')\n",
    "        \n",
    "        # Ensure the directory exists\n",
    "        os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "        \n",
    "        if self.feature_list_for_scale is None:\n",
    "            # Cập nhật danh sách đặc trưng nếu chưa được gán\n",
    "            self.feature_list_for_scale = [\n",
    "                'hour', 'day', 'month', 'day_of_week', 'day_of_year',\n",
    "                'temperature_lag_1', 'temperature_lag_2', 'temperature_lag_3',\n",
    "                'temperature_rolling_mean_3', 'temperature_rolling_mean_6', 'temperature_rolling_mean_12',\n",
    "                'humidity_lag_1', 'humidity_lag_2', 'humidity_lag_3',\n",
    "                'humidity_rolling_mean_3', 'humidity_rolling_mean_6', 'humidity_rolling_mean_12',\n",
    "                'wind_speed_lag_1', 'wind_speed_lag_2', 'wind_speed_lag_3',\n",
    "                'wind_speed_rolling_mean_3', 'wind_speed_rolling_mean_6', 'wind_speed_rolling_mean_12',\n",
    "                'pressure_lag_1', 'pressure_lag_2', 'pressure_lag_3',\n",
    "                'pressure_rolling_mean_3', 'pressure_rolling_mean_6', 'pressure_rolling_mean_12',\n",
    "                'precipitation_lag_1', 'precipitation_lag_2', 'precipitation_lag_3',\n",
    "                'precipitation_rolling_mean_3', 'precipitation_rolling_mean_6', 'precipitation_rolling_mean_12',\n",
    "                'cloud_lag_1', 'cloud_lag_2', 'cloud_lag_3',\n",
    "                'cloud_rolling_mean_3', 'cloud_rolling_mean_6', 'cloud_rolling_mean_12',\n",
    "                'uv_index_lag_1', 'uv_index_lag_2', 'uv_index_lag_3',\n",
    "                'uv_index_rolling_mean_3', 'uv_index_rolling_mean_6', 'uv_index_rolling_mean_12',\n",
    "                'visibility_lag_1', 'visibility_lag_2', 'visibility_lag_3',\n",
    "                'visibility_rolling_mean_3', 'visibility_rolling_mean_6', 'visibility_rolling_mean_12',\n",
    "                'rain_probability_lag_1', 'rain_probability_lag_2', 'rain_probability_lag_3',\n",
    "                'rain_probability_rolling_mean_3', 'rain_probability_rolling_mean_6', 'rain_probability_rolling_mean_12',\n",
    "                'dewpoint_lag_1', 'dewpoint_lag_2', 'dewpoint_lag_3',\n",
    "                'dewpoint_rolling_mean_3', 'dewpoint_rolling_mean_6', 'dewpoint_rolling_mean_12',\n",
    "                'airport_code_encoded'\n",
    "            ]\n",
    "            print(\"Updated 'feature_list_for_scale' before saving the model.\")\n",
    "        \n",
    "        # Lưu mô hình và thông tin liên quan\n",
    "        joblib.dump({\n",
    "            'models': self.models, \n",
    "            'scalers': self.scalers, \n",
    "            'feature_list_for_scale': self.feature_list_for_scale\n",
    "        }, path, compress=4)\n",
    "        \n",
    "        print(f\"Models and feature list saved successfully to {path}.\")\n",
    "    \n",
    "    def load_models(self, path=models_path):\n",
    "        \"\"\"Load trained models.\"\"\"\n",
    "        data = joblib.load(path)\n",
    "        self.models = data['models']\n",
    "        self.scalers = data['scalers']\n",
    "        self.feature_list_for_scale = data['feature_list_for_scale']\n",
    "        \n",
    "    def print_evaluation_metrics(self):\n",
    "        \"\"\"Print comprehensive evaluation metrics for all models.\"\"\"\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(f\"{'MODEL EVALUATION METRICS':^80}\")\n",
    "        print(\"=\"*80)\n",
    "        print(f\"{'Target':<15} | {'RMSE':^12} | {'MAE':^12} | {'R²':^12} | {'MAPE (%)':^12}\")\n",
    "        print(\"-\"*80)\n",
    "        \n",
    "        for target, metrics in self.metrics.items():\n",
    "            rmse = f\"{metrics['rmse']:.4f}\" if isinstance(metrics['rmse'], (int, float)) else metrics['rmse']\n",
    "            mae = f\"{metrics['mae']:.4f}\" if isinstance(metrics['mae'], (int, float)) else metrics['mae']\n",
    "            r2 = f\"{metrics['r2']:.4f}\" if isinstance(metrics['r2'], (int, float)) else metrics['r2']\n",
    "            mape = f\"{metrics['mape']:.4f}\" if isinstance(metrics['mape'], (int, float)) else metrics['mape']\n",
    "            \n",
    "            print(f\"{target:<15} | {rmse:^12} | {mae:^12} | {r2:^12} | {mape:^12}\")\n",
    "        \n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        # Also print top 5 most important features for each model\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(f\"{'TOP 5 MOST IMPORTANT FEATURES':^80}\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        for target, importances in self.feature_importances.items():\n",
    "            print(f\"\\nModel: {target}\")\n",
    "            sorted_features = sorted(importances.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "            for i, (feature, importance) in enumerate(sorted_features, 1):\n",
    "                print(f\"{i}. {feature:<20}: {importance:.4f}\")\n",
    "    \n",
    "    def generate_summary_report(self, output_path=None):\n",
    "        \"\"\"Generate a comprehensive summary report of model performance.\"\"\"\n",
    "        if output_path is None:\n",
    "            output_path = os.path.join(project_root, 'backend', 'ml', 'models', 'model_evaluation_report.txt')\n",
    "        \n",
    "        with open(output_path, 'w') as f:\n",
    "            f.write(\"=\"*80 + \"\\n\")\n",
    "            f.write(f\"{'WEATHER PREDICTION MODEL EVALUATION REPORT':^80}\\n\")\n",
    "            f.write(f\"{'Generated on: ' + pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S'):^80}\\n\")\n",
    "            f.write(\"=\"*80 + \"\\n\\n\")\n",
    "            \n",
    "            # Write model metrics\n",
    "            f.write(\"MODEL PERFORMANCE METRICS\\n\")\n",
    "            f.write(\"-\"*80 + \"\\n\")\n",
    "            f.write(f\"{'Target':<15} | {'RMSE':^12} | {'MAE':^12} | {'R²':^12} | {'MAPE (%)':^12}\\n\")\n",
    "            f.write(\"-\"*80 + \"\\n\")\n",
    "            \n",
    "            for target, metrics in self.metrics.items():\n",
    "                rmse = f\"{metrics['rmse']:.4f}\" if isinstance(metrics['rmse'], (int, float)) else metrics['rmse']\n",
    "                mae = f\"{metrics['mae']:.4f}\" if isinstance(metrics['mae'], (int, float)) else metrics['mae']\n",
    "                r2 = f\"{metrics['r2']:.4f}\" if isinstance(metrics['r2'], (int, float)) else metrics['r2']\n",
    "                mape = f\"{metrics['mape']:.4f}\" if isinstance(metrics['mape'], (int, float)) else metrics['mape']\n",
    "                \n",
    "                f.write(f\"{target:<15} | {rmse:^12} | {mae:^12} | {r2:^12} | {mape:^12}\\n\")\n",
    "            \n",
    "            f.write(\"\\n\\n\")\n",
    "            \n",
    "            # Write feature importances\n",
    "            f.write(\"FEATURE IMPORTANCE ANALYSIS\\n\")\n",
    "            f.write(\"-\"*80 + \"\\n\")\n",
    "            \n",
    "            for target, importances in self.feature_importances.items():\n",
    "                f.write(f\"\\nModel: {target}\\n\")\n",
    "                sorted_features = sorted(importances.items(), key=lambda x: x[1], reverse=True)\n",
    "                for i, (feature, importance) in enumerate(sorted_features, 1):\n",
    "                    f.write(f\"{i}. {feature:<20}: {importance:.4f}\\n\")\n",
    "                f.write(\"\\n\")\n",
    "        \n",
    "        print(f\"Summary report generated at: {output_path}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d016da99",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Initialize predictor\n",
    "    predictor = WeatherPredictor()\n",
    "    \n",
    "    # Prepare data\n",
    "    X, y_dict, feature_list_for_scale = predictor.prepare_data(dataset_path)\n",
    "\n",
    "    # Train models\n",
    "    metrics = predictor.train(X, y_dict, feature_list_for_scale)\n",
    "    \n",
    "    # Print metrics\n",
    "    for target, metric in metrics.items():\n",
    "        print(f\"{target} - RMSE: {metric['rmse']}, R²: {metric['r2']}\")\n",
    "    \n",
    "    # Save models\n",
    "    predictor.save_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ab8c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/14 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for temperature...\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
